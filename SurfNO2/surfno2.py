#!/bin/python
import sys
import os
import numpy as np
import pandas as pd
import datetime as dt
import xarray as xr
import xgboost as xgb
import plotly.express as px
import requests
from dateutil.relativedelta import relativedelta 
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt

M2_TEMPLATE = "/home/ftei-dsw/Projects/SurfNO2/data/M2/{c}/small/*.{c}.%Y%m*.nc4"
COLLECTIONS = ["tavg1_2d_flx_Nx","tavg1_2d_lfo_Nx","tavg1_2d_slv_Nx"]
OPENAQ_TEMPLATE = 'https://docs.openaq.org/v2/measurements?date_from={Y1}-{M1}-01T00%3A00%3A00%2B00%3A00&date_to={Y2}-{M2}-01T00%3A00%3A00%2B00%3A00&limit=10000&page=1&offset=0&sort=asc&radius=1000&location_id={ID}&parameter={PARA}&order_by=datetime'


class ObsSite:
    def __init__(self,location_id,read_obs=False,**kwargs):
        '''
        Initialize ObsSite object.
        '''
        self._init_site(location_id)
        if read_obs:
            self.read_obs(**kwargs)


    def read_obs_and_mod(self,**kwargs):
        '''Convenience wrapper to read both observations and model data'''
        self.read_obs(**kwargs)
        self.read_mod(**kwargs)
        return


    def read_obs(self,**kwargs):
        '''Wrapper routine to read observations'''
        obs = self._read_openaq(**kwargs)
        if obs is None:
            print('Warning: no observations found!')
            return
        ilat = obs['lat'].median()
        ilon = obs['lon'].median()
        iname = obs['location'].values[0]
        print('Found {:d} observations for {:} (lon={:.2f}; lat={:.2f})'.format(obs.shape[0],iname,ilon,ilat))
        self._lat = ilat if self._lat is None else self._lat 
        self._lon = ilon if self._lon is None else self._lon 
        assert(ilat==self._lat)
        assert(ilon==self._lon)
        self._name = iname if self._name is None else self._name
        assert(iname==self._name)
        self._obs = self._obs.merge(obs,how='outer') if self._obs is not None else obs
        return


    def read_mod(self,**kwargs):
        '''Wrapper routine to read model data'''
        assert(self._lon is not None and self._lat is not None)
        if 'start' not in kwargs:
            kwargs['start'] = self._obs['time'].min()
        if 'end' not in kwargs:
            kwargs['end'] = self._obs['time'].max()
        mod = self._read_merra2(self._lon,self._lat,**kwargs)
        self._mod = self._mod.merge(mod,how='outer') if self._mod is not None else mod
        return


    def train(self,target_var='value',skipvar=['time','location','lat','lon'],test_size=0.2,**kwargs):
        '''Train XGBoost model using data in memory'''
        dat = self._merge(**kwargs) 
        yvar = [target_var]
        blacklist = yvar + skipvar
        xvar = [i for i in dat.columns if i not in blacklist]
        X = dat[xvar]
        y = dat[yvar]
        Xtrain, Xtest, ytrain, ytest = train_test_split( X, y, test_size=test_size)
        train = xgb.DMatrix(Xtrain,ytrain)
        print('training model ...')
        param = {'booster':'gbtree'}
        bst = xgb.train(param,train)
        ptrain = bst.predict(xgb.DMatrix(Xtrain))
        ptest = bst.predict(xgb.DMatrix(Xtest))
        ytrainf = np.array(ytrain).flatten()
        ytestf = np.array(ytest).flatten()
        print('Training:')
        print('r2 = {:.2f}'.format(r2_score(ytrainf,ptrain)))
        print('nrmse = {:.2f}'.format( sqrt(mean_squared_error(ytrainf,ptrain))/np.std(ytrainf)))
        print('nmb = {:.2f}'.format(np.sum(ptrain-ytrainf)/np.sum(ytrainf)))
        print('Test:')
        print('r2 = {:.2f}'.format(r2_score(ytestf,ptest)))
        print('nrmse = {:.2f}'.format( sqrt(mean_squared_error(ytestf,ptest))/np.std(ytestf)))
        print('nmb = {:.2f}'.format(np.sum(ptest-ytestf)/np.sum(ytestf)))
        self._bst = bst
        self._xcolumns = X.columns
        return


    def predict(self,**kwargs):
        '''Make prediction for given time window and return predicted values along with observations'''
        dat = self._merge(**kwargs)
        pred = self._bst.predict(xgb.DMatrix(dat[self._xcolumns]))
        df = dat[['time','value']].copy()
        df['prediction'] = pred
        df.rename(columns={'value':'observation'},inplace=True)
        return df


    def plot(self,df,**kwargs):
        '''Make plot of prediction vs. observation, as generated by self.predict()'''
        title = 'Site = {0} ({1:.2f}N, {2:.2f}E)'.format(self._name,self._lat,self._lon)
        fig = px.line(df,x='time',y=['observation','prediction'],labels={'value':r'$\text{NO}_{2}\,[\text{ppbv}]$'},title=title)
        return fig


    def _merge(self,start=None,end=None,mod_blacklist=['lat','lon']):
        '''Merge model and observation and limit to given time window'''
        assert(self._mod is not None and self._obs is not None)
        # toss model variables that are blacklisted. By default, this is lat/lon,
        # which are rounded to grid cell edges.
        ivars = [i for i in self._mod.columns if i not in mod_blacklist] 
        dat = self._mod[ivars].merge(self._obs,on=['time'])
        start = start if start is not None else dat['time'].min()
        end = end if end is not None else dat['time'].max()
        idat = dat.loc[(dat['time']>=start)&(dat['time']<=end)]
        return idat


    def _init_site(self,location_id):
        '''Create an empty site object'''
        self._id   = location_id
        self._lat  = None
        self._lon  = None
        self._name = None
        self._obs  = None
        self._mod  = None
        return


    def _read_merra2(self,ilon,ilat,start,end,collections=COLLECTIONS,m2_template=M2_TEMPLATE):
        '''Read MERRA-2 data'''
        dfs = []
        for c in collections:
            template = m2_template.replace("{c}",c)
            ifiles = start.strftime(template)
            print('Reading {}...'.format(c))
            ids = xr.open_mfdataset(ifiles).sel(lon=ilon,lat=ilat,method='nearest').sel(time=slice(start,end)).load().to_dataframe().reset_index()
            dfs.append(ids)
        mod = dfs[0]
        for d in dfs[1:]:
            mod = mod.merge(d,on=['time','lat','lon'])
        mod['time'] = [pd.to_datetime(i) for i in mod['time']]
        mod['month'] = [i.month for i in mod['time']]
        mod['hour'] = [i.hour for i in mod['time']]
        mod['weekday'] = [i.weekday() for i in mod['time']]
        return mod


    def _read_openaq(self,para='no2',start=dt.datetime(2018,1,1),end=None):
        '''Read OpenAQ observations'''
        end = start+relativedelta(years=1) if end is None else end
        url = OPENAQ_TEMPLATE.replace('{ID}',str(self._id)).replace('{PARA}',para).replace('{Y1}',str(start.year)).replace('{M1}','{:02d}'.format(start.month)).replace('{D1}','{:02d}'.format(start.day)).replace('{Y2}',str(end.year)).replace('{M2}','{:02d}'.format(end.month)).replace('{D2}','{:02d}'.format(end.day))
        print('Quering {}'.format(url))
        r = requests.get( url )
        assert(r.status_code==200)
        allobs = pd.json_normalize(r.json()['results'])
        allobs['time'] = [dt.datetime.strptime(i,'%Y-%m-%dT%H:%M:%S+00:00') for i in allobs['date.utc']]
        obs = allobs.loc[(allobs['parameter']==para)&(~np.isnan(allobs['value']))].copy()
        obs.loc[obs['unit']=='ppm','value'] = obs.loc[obs['unit']=='ppm','value']*1000.0
        obs = obs[['time','location','value','coordinates.latitude','coordinates.longitude',]].copy()
        obs['time'] = [i + dt.timedelta(minutes=30) for i in obs['time']]
        obs.rename(columns={'coordinates.latitude':'lat','coordinates.longitude':'lon'},inplace=True)
        return obs
